## 병무청 AI 상담 시스템: 질문-답변 생성 프로세스 분석 (LangGraph 기반)

이 문서는 사용자가 질문을 입력했을 때, `rag_page` 내의 코드들이 어떻게 상호작용하여 최종 답변을 생성하는지 각 단계별로 상세히 설명합니다. 이 시스템은 **LangGraph**를 사용하여 여러 단계를 체계적인 워크플로우로 구성합니다.

### 전체 프로세스 요약

```
┌──────────────┐   1. 질문     ┌────────────────────────┐   2. 질문 재작성 ┌──────────────────────┐
│      사용자   │   ──────────>│      app.py            │───────────────> │ LLM (32B) - ReWriter │
│              │    <──────────┤ (FastAPI, LangGraph)   ├<─────────────── ┤         노드         │
└──────────────┘  10. 답변     └──────────┬─────────────┘                 └───────질문 재작성─────┘
                                          │ 3. 재작성된 질문
                                          ▼
                               ┌────────────────────────────┐
                               │ LLM (8B) - Decomposer 노드 │
                               └────────────┬─────────────┘
                                            │ 4. 하위 질문들 생성
                                            ▼
┌────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐
│                            Recursive Search 노드 (하위 질문 개수만큼 반복)                                           │
│                                                                                                                    │
│   ┌────────────────────┐ 5. 멀티 쿼리   ┌──────────────────┐ 6. 문서 검색   ┌──────────┐7. LLM 리랭킹  ┌──────────┐  │
│   │   현재 하위 질문    │─────────────> │ LLM (32B) - Multi├─────────────> │ FAISS &   ├────────────> │ LLM (8B)  │ │
│   │                    │<──────────────┤   Query 생성      │<─────────────┤   BM25    │<──────────── │ Reranker  │ │
│   └────────────────────┘               └──────────────────┘               └──────────┘               └──────────┘  │
│                                                                                                                    │
└────────────────────────────────────────────┬───────────────────────────────────────────────────────────────────────┘
                                             │ 8. 최종 관련 문서 목록
                                             ▼
┌─────────────────────┐   9. 프롬프트 구성 및 답변 생성 ┌──────────────────────────┐
│      app.py         │──────────────────────────────>│  LLM (32B) - Generate    │
│(FastAPI, LangGraph) │                               │      Answer 노드         │
└─────────────────────┘                               └──────────────────────────┘
```

---

### 1. 사전 준비 단계: 벡터 스토어(Vector Store) 생성

답변 생성에 필요한 정보를 미리 색인하고 저장하는 과정입니다. 이 과정은 `app.py` 실행 시 자동으로 수행됩니다.

**관련 파일:** `simple_rag_with_pages.py`

1.  **PDF 문서 수집**: `data` 폴더에 있는 모든 `.pdf` 파일을 수집합니다.
2.  **텍스트 추출 및 재귀적 청킹**: `pdfplumber`로 PDF 텍스트를 추출하고, `RecursiveCharacterTextSplitter`를 사용해 고정 크기 기반으로 청크를 분할합니다. 이는 의미적 경계를 고려하면서도 일정한 크기를 유지하는 분할 방식입니다.
3.  **임베딩(Embedding)**: 각 텍스트 청크를 `OllamaEmbeddings` (`bge-m3:latest` 모델)를 통해 의미를 담은 벡터로 변환합니다.
4.  **FAISS 벡터 스토어 생성**: 생성된 벡터들을 빠른 검색을 위해 `FAISS` 벡터 스토어에 저장합니다. 이와 별도로 키워드 검색을 위한 `BM25Retriever`도 준비됩니다.

---

### 2. 사용자 질문 처리 및 답변 생성 과�� (LangGraph 워크플로우)

사용자가 질문을 입력하면, `app.py`에 정의된 **LangGraph** 워크플로우가 시작됩니다.

**관련 파일:** `app.py`

#### **1단계: 사용자 입력 및 워크플로우 시작**

*   사용자가 `chat.html`에서 질문을 입력하면, `process_rag_query` 함수가 호출되어 LangGraph 워크플로우를 실행합니다.

#### **2단계: ReWriter 노드 (질문 재작성)**

*   **목표**: 대화의 맥락을 이용해 모호한 후속 질문을 명확하게 만듭니다.
*   **과정**:
    1.  `re_writer` 함수는 현재 대화 기록과 새로운 질문을 `re_write_prompt` 템플릿에 결합합니다.
    2.  **`llm_model_32b`** 가 이 프롬프트를 받아, "그건 어떻게 지원해?" 같은 질문을 "카투사는 어떻게 지원해?"와 같이 구체적인 질문으로 재작성합니다.
    3.  대화 기록이 없으면 이 단계는 건너뜁니다.

#### **3단계: Question Decomposer 노드 (하위 질문 생성)**

*   **목표**: 하나의 질문에서 여러 정보 검색 포인트를 도출합니다.
*   **과정**:
    1.  `question_decomposer` 함수는 재작성된 질문을 `question_decomposer_prompt`와 함께 **`llm_model_8b`** 에 전달합니다.
    2.  LLM은 원본 질문을 포함하여, 답변을 풍부하게 만들 수 있는 2개의 추가 하위 질문을 생성합니다. (예: "카투사 지원 자격" -> ["카투사 지원 자격", "카투사 어학 성적 기준", "카투사 신체검사 조건"])

#### **4단계: Recursive Search 노드 (재귀적 문서 검색)**

*   **목표**: 생성된 모든 하위 질문에 대해 가장 관련성 높은 문서를 찾습니다. 이 노드는 하위 질문의 개수만큼 반복 실행됩니다.
*   **과정** (`enhanced_multi_search` 함수):
    1.  **멀티 쿼리 생성**: 현재 처리할 하위 질문을 **`llm_model_32b`** 와 `multi_query_prompt`를 이용해 2개의 다른 검색어로 변환합니다. (예: "카투사 혜택" -> ["카투사 혜택", "카투사 복지"])
    2.  **문서 검색**: 생성된 모든 검색어를 사용해 `fast_search` 함수로 FAISS(의미)와 BM25(키워드)에서 관련 문서를 검색합니다.
    3.  **LLM 리랭킹**: 검색된 모든 문서와 원본 하위 질문을 `semantic_reranking_prompt`와 함께 **`llm_model_8b`** 에 보냅니다. LLM은 각 문서가 질문과 얼마나 관련 있는지 1~10점으로 평가합니다.
    4.  **문서 선별**: 점수가 8점 이상인 문서들만 최종 후보로 선택합니다.
    5.  모든 하위 질문에 대해 위 과정이 끝나면, 수집된 모든 관련 문서를 하나로 모읍니다.

#### **5단계: Generate Answer 노드 (답변 생성)**

*   **목표**: 수집된 모든 정보를 바탕으로 최종 답변을 생성합니다.
*   **과정**:
    1.  `generate_answer` 함수는 4단계에서 선별된 모든 문서, 원본 질문, 대화 기록을 `generate_prompt` 템플릿에 삽입합니다.
    2.  이 최종 프롬프트는 주력 모델인 **`llm_model_generate` (Qwen2.5-32B-Instruct)** 로 전달됩니다.
    3.  LLM은 "당신은 병무청 AI 상담원입니다"라는 지시에 따라, 제공된 문서 내용에만 근거하여 정확하고 상세한 답변을 생성합니다.

#### **6단계: 답변 반환**

*   생성된 최종 답변은 `process_rag_query` 함수의 결과로 반환되어 사용자 화면에 표시됩니다. 이 과정에서 `addMessage` 자바스크립트 함수가 답변 텍스트의 서식(강조, 출처 등)을 처리합니다.
